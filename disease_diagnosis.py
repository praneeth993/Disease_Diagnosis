# -*- coding: utf-8 -*-
"""Disease_Diagnosis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18juZG8NUWgmA3AnqotxcbZFaVMj9VnXP
"""

!unzip sample_data/dataset

import math
import pandas as pd

df=pd.read_csv('dataset.csv')
df

df.info

import numpy as np
import math
x={'',} # Set of all the unique set of symtoms in the dataset
for i in df.keys():
  if i !='Disease':
    x.update(df[i].values.tolist())
print(x)
li=[]
for i in x:
  if i!='':
    li.append(i)
#li=np.array(li)
print(li)

# Modifying the given dataset such that each row represents the symtom vector for the disease
d={}
i=0
while i<len(df['Disease']):
  if i==0:
    d['Disease']=[df['Disease'][i]]
  else:
    d['Disease'].append(df['Disease'][i])
  for j in li:
    if j in d.keys():
      if j in df.loc[i].tolist(): #If the symtom is present in the disease then that coreesponding entry will be 1 else 0
        d[j].append(1)
      else:
        d[j].append(0)
    else:
      if j in df.loc[i].tolist():
        d[j]=[1]
      else:
        d[j]=[0]
  i=i+1
print(d)

# Converting the dictionary to the dataframe
df1=pd.DataFrame(d)
df1=df1.drop(math.nan,axis=1)
df1

#Calculating the Entropy of the dataset
def entropy(arg):
  pr={}
  for i in arg:
    if i in pr.keys():
      pr[i] +=1
    else:
      pr[i]=1
  l=pr.values()
  sum=0
  for s in l:
    sum +=s
  hs=0
  for j in l:
    hs=hs+((j/sum)*math.log(j/sum,2))
  hs=-hs
  return (hs)

# Testing the Entropy function on a dummy case
en=entropy(df1['Disease'].values.tolist())
print(en)

# Function to Calculate weighted entropy
# Information_Gain=Entropy-weighted entropy
def weighted_entropy(index,value,feature):
  s1=[]
  s2=[]
  for  i in index:
    if df1[feature][i]==1:
      s1.append(df1['Disease'][i])
    elif df1[feature][i]==0:
      s2.append(df1['Disease'][i])
  wg=((len(s1)/(len(s1)+len(s2)))*entropy(s1))+((len(s2)/(len(s1)+len(s2)))*entropy(s2))
  return wg

#Testing the weighted_entropy function on a dummy case
we=weighted_entropy([num for num in range(len(df1['Disease'])//2)],df1[' fluid_overload'].values.tolist(),' fluid_overload')
print(we)

# defining a Class to create a node of a symptom feature
class node:
  def __init__(self,Node,p_disease):
    self.feature=Node # Used to store the best_splittting feature in the node
    self.l=None # Used to define the left sub-tree of the current node
    self.R=None # Used to define the right sub-tree of the current node
    self.p_disease=p_disease
  def __str__(self):
    print(self.feature)
    print(self.p_disease)

# defining a create_tree function to build a tree by splitting via best feature
# Which is having the maximum information_gain
disease_index=[num for num in range(len(df1['Disease'].tolist()))]
sym=df1.keys().tolist()
sym.remove("Disease")
def create_tree(arg,value,d=0):
  # Limitting the minimum number of classes in the set to be 1
  if len(arg)<1:
    return None
  # Setting the maximum depth of graph as 5
  if d>5:
    return None
  entopy_list=[]
  for i in arg:
    entopy_list.append(df1['Disease'][i])
  # Evaluating the entropy of the complete dataset
  hs=entropy(entopy_list)
  feature=0
  IG={}
  # Iterating over all the features to calculate their information gain
  for i in value:
    we=weighted_entropy(arg,df1[i].values.tolist(),i)
    ig=hs-we # information_gain
    IG[i]=ig
  max_ig=max(IG.values())
  # Selecting the feature with maximum information gain
  for i in IG.keys():
    if IG[i]==max_ig:
      feature=i
      print(feature)
      break
  classes={}
  # Calculating the Dominant class for each feature node
  if len(arg)>0:
    for i in arg:
      if df1['Disease'][i] in classes.keys():
        classes[df1['Disease'][i]] +=1
      else:
        classes[df1['Disease'][i]] =1
    max_class=max(classes.values())
    for i in classes.keys():
      if classes[i]==max_class:
        p_disease=i
        break
  i=0
  left=[] # List stores the diseases not having a particular symtom
  right=[] # Stores the diseases having a particular symtom
  for i in arg:
    if df1[feature][i]==0:
      left.append(i)
    elif df1[feature][i]==1:
      right.append(i)
  # Creating the node with the required feature used for splitting and the dominant predicted disease
  classify=node(feature,p_disease)
  value.remove(feature)
  # Providing values to the lest and right children of the node
  # By recurrsively calling the create_tree function
  classify.l=create_tree(left,value,d+1)
  classify.R=create_tree(right,value,d+1)
  return classify # Returns the node of each level

#tr at last will be root node
tr=create_tree(disease_index,sym)

# Prediction Function
def prd(Node,data):
  prediction=None
  i=0
  # crnt is intialized with the root node value
  crnt=Node
  while True:
    # If the feature of the node is in the test list then current node is replaced by its right child
    # Else current node is replaced by its left child
    if crnt.feature in data:
      if crnt.R!=None:
        crnt=crnt.R
        prediction=crnt.p_disease
      else:
        prediction=crnt.p_disease # prediction stores the dominant class of each node
        break
    else:
      if crnt.l!=None:
        crnt=crnt.l
        prediction=crnt.p_disease
      else:
        prediction=crnt.p_disease
        break
  return prediction

# Counter variable to keep a count of diseases correctly Identified
counter=0
for i in range(len(df1['Disease'])):
  test=[]
  x=df1.loc[i].tolist()
  actual=x[0]
  j=1
  while j<len(x):
    if x[j]==1:
      # Creating a test dataset to predict the disease
      test.append(df1.keys().tolist()[j])
    j=j+1
  output=prd(tr,test)
  # Checking the actual and predicted labels of the test data
  if output==actual:
    counter+=1
print("Accuracy = ",(counter*100)/len(df1['Disease'])) # Calculating the accuracy
# To determine the accuracy we iterated over the modified dataset to create a test dataset
# And then we predicted the disease for each of the test lists
# we have the actual and predicted labels to calculate the accuracy finally

data=input("Enter the symtoms (Use , as separator) :") .split(",") # We took the list of symptoms by user
output=prd(tr,data) # predict the disease for given list of symptoms
print("Predicted Disease is : ",output)

